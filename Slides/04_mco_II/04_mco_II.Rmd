---
title: "MCO: inferencia y m√°s"
subtitle: "Econometr√≠a I"
author: "Paula Pereda (ppereda@correo.um.edu.uy)"
date: "10 de setiembre de 2021"
output:
  xaringan::moon_reader:
    css: ['default', 'metropolis', 'metropolis-fonts', 'my-css.css']
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: inverse, middle

```{r Setup, include = F}
options(htmltools.dir.version = FALSE)
library(pacman)
p_load(broom, latex2exp, ggplot2, ggthemes, ggforce, viridis, dplyr, 
       magrittr, knitr, tidyverse, parallel, faux, eulerr)

# Knitr options
opts_chunk$set(
  comment = ">",
  fig.align = "center",
  fig.height = 7,
  fig.width = 10.5,
  warning = F,
  message = F
)

# A blank theme for ggplot
theme_empty <- theme_bw() + theme(
  line = element_blank(),
  rect = element_blank(),
  strip.text = element_blank(),
  axis.text = element_blank(),
  plot.title = element_blank(),
  axis.title = element_blank(),
  plot.margin = structure(c(0, 0, -0.5, -1), unit = "lines", valid.unit = 3L, class = "unit"),
  legend.position = "none")

theme_simple <- theme_bw() + theme(
  line = element_blank(),
  panel.grid = element_blank(),
  rect = element_blank(),
  strip.text = element_blank(),
  axis.text.x = element_text(size = 14),
  axis.text.y = element_blank(),
  axis.ticks = element_blank(),
  plot.title = element_blank(),
  axis.title = element_blank(),
  legend.position = "none")

theme_axes <- theme_empty + theme(
  axis.title = element_text(size = 18),
  plot.margin = structure(c(0, 0, 0.1, 0), unit = "lines", valid.unit = 3L, class = "unit"))
```

```{R, colors, include = F}
# Define pink color
red_pink <- "#e64173"
turquoise <- "#20B2AA"
orange <- "#FFA500"
red <- "#fb6107"
blue <- "#2b59c3"
green <- "#8bb174"
grey_light <- "grey70"
grey_mid <- "grey50"
grey_dark <- "grey20"
purple <- "#6A5ACD"
```

```{R, gen dataset, include = F, cache = T}
# Set population and sample sizes
n_p <- 100
n_s <- 30
# Set the seed
set.seed(12468)
# Generate data
pop_df <- tibble(
  i = 3,
  x = rnorm(n_p, mean = 5, sd = 1.5),
  e = rnorm(n_p, mean = 0, sd = 1),
  y = i + 0.5 * x + e,
  row = rep(1:sqrt(n_p), times = sqrt(n_p)),
  col = rep(1:sqrt(n_p), each = sqrt(n_p)),
  s1 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s))),
  s2 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s))),
  s3 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s)))
)
# Regressions
lm0 <- lm(y ~ x, data = pop_df)
lm1 <- lm(y ~ x, data = filter(pop_df, s1 == T))
lm2 <- lm(y ~ x, data = filter(pop_df, s2 == T))
lm3 <- lm(y ~ x, data = filter(pop_df, s3 == T))
# Simulation
set.seed(12468)
sim_df <- mclapply(mc.cores = 10, X = 1:1e4, FUN = function(x, size = n_s) {
  lm(y ~ x, data = pop_df %>% sample_n(size = size)) %>% tidy()
}) %>% do.call(rbind, .) %>% as_tibble()
```


# Regresi√≥n m√∫ltiple

---
layout: true
# Regresi√≥n m√∫ltiple

---

## M√°s variables explicativas


Pasamos de la **regresi√≥n lineal simple** (una .pink[variable de resultado] y una .purple[variable explicativa])

$$ \color{#e64173}{y_i} = \beta_0 + \beta_1 \color{#6A5ACD}{x_i} + u_i $$

a la tierra de la **regresi√≥n lineal m√∫ltiple** (un .pink[variable de resultado] y varios .purple[variables explicativas])

$$ \color{#e64173}{y\_i} = \beta\_0 + \beta\_1 \color{#6A5ACD}{x\_{1i}} + \beta\_2 \color{#6A5ACD}{x\_{2i}} + \cdots + \beta\_k \color{#6A5ACD}{x\_{ki}} + u\_i $$

--

**¬øPor qu√©?**
--
 Podemos explicar mejor la variaci√≥n en $y$, mejorar las predicciones, evitar el sesgo de variables omitidas, ...

---

```{R, gen data, cache = T, include = F}
n <- 1e2
set.seed(1989)
gen_df <- tibble(
  x1 = runif(n = n, min = -3, max = 3),
  x2 = sample(x = c(F, T), size = n, replace = T),
  u  = rnorm(n = n, mean = 0, sd = 1),
  y  = -0.5 + x1 + x2 * 4 + u
)
mean_a <- filter(gen_df, x2 == F)$y %>% mean()
mean_b <- filter(gen_df, x2 == T)$y %>% mean()
gen_df %<>% mutate(y_dm = y - mean_a * (x2 == F) - mean_b * (x2 == T))
```

$y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + u_i \quad$ $x_1$ es continua $\quad x_2$ es categ√≥rica

```{R, mult reg plot 1, dev = "svg", echo = F, fig.height = 6.25}
ggplot(data = gen_df, aes(y = y, x = x1, color = x2, shape = x2)) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = TeX("$y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = TeX("$x_1$"), size = 8) +
geom_point(size = 3) +
ylim(c(-4.5, 8)) +
theme_empty +
scale_color_manual(
  expression(x[2]),
  values = c("darkslategrey", red_pink),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(x[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  legend.position = "bottom",
  text = element_text(size = 20)
)
```

---
count: false

La intercepci√≥n y la variable categ√≥rica $x_2$ controlan las medias de los grupos.

```{R, mult reg plot 2, dev = "svg", echo = F, fig.height = 6.25}
ggplot(data = gen_df, aes(y = y, x = x1, color = x2, shape = x2)) +
geom_hline(yintercept = mean_a, color = "darkslategrey", alpha = 0.5) +
geom_hline(yintercept = mean_b, color = red_pink, alpha = 0.5) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = TeX("$y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = TeX("$x_1$"), size = 8) +
geom_point(size = 3) +
ylim(c(-4.5, 8)) +
theme_empty +
scale_color_manual(
  expression(x[2]),
  values = c("darkslategrey", red_pink),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(x[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  legend.position = "bottom",
  text = element_text(size = 20)
)
```

---
count: false

Con los medias de los grupos eliminados:

```{R, mult reg plot 3, dev = "svg", echo = F, fig.height = 6.25}
ggplot(data = gen_df %>% mutate(y = y - 4 * x2), aes(y = y_dm, x = x1)) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = TeX("$y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = TeX("$x_1$"), size = 8) +
geom_point(size = 3, aes(color = x2, shape = x2)) +
ylim(c(-4.5, 8)) +
theme_empty +
scale_color_manual(
  expression(x[2]),
  values = c("darkslategrey", red_pink),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(x[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  legend.position = "bottom",
  text = element_text(size = 20)
)
```

---
count: false

$\hat{\beta}_1$ estima la relaci√≥n la relaci√≥n entre $y$ y $x_1$ despu√©s de controlar por $x_2$.

```{R, mult reg plot 4, dev = "svg", echo = F, fig.height = 6.25}
ggplot(data = gen_df %>% mutate(y = y - 4 * x2), aes(y = y_dm, x = x1)) +
geom_smooth(method = lm, se = F, color = "orange") +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = TeX("$y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = TeX("$x_1$"), size = 8) +
geom_point(size = 3, aes(color = x2, shape = x2)) +
ylim(c(-4.5, 8)) +
theme_empty +
scale_color_manual(
  expression(x[2]),
  values = c("darkslategrey", red_pink),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(x[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  legend.position = "bottom",
  text = element_text(size = 20)
)
```

---
count: false

Otra manera de pensar sobre esto:

```{R, mult reg plot 5, dev = "svg", echo = F, fig.height = 6.25}
ggplot(data = gen_df, aes(y = y, x = x1, color = x2, shape = x2)) +
geom_smooth(method = lm, se = F) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = TeX("$y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = TeX("$x_1$"), size = 8) +
geom_point(size = 3) +
ylim(c(-4.5, 8)) +
theme_empty +
scale_color_manual(
  expression(x[2]),
  values = c("darkslategrey", red_pink),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(x[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  legend.position = "bottom",
  text = element_text(size = 20)
)
```

---
Mirar a nuestro estimador puede ayudar, tambi√©n. 

Para una regresi√≥n simple $y_i = \beta_0 + \beta_1 x_i + u_i$

$$
\begin{aligned}
  \hat{\beta}_1 &= \\[0.3em]
  &= \dfrac{\sum_i \left( x_i - \overline{x} \right) \left( y_i - \overline{y} \right)}{\sum_i \left( x_i -\overline{x} \right)} \\[0.3em]
  &= \dfrac{\sum_i \left( x_i - \overline{x} \right) \left( y_i - \overline{y} \right)/(n-1)}{\sum_i \left( x_i -\overline{x} \right) / (n-1)} \\[0.3em]
  &= \dfrac{\mathop{\hat{\text{Cov}}}(x,\,y)}{\mathop{\hat{\text{Var}}} \left( x \right)}
\end{aligned}
$$

---
El estimador de regresi√≥n simple:

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(x,\,y)}{\mathop{\hat{\text{Var}}} \left( x \right)} $$

Pasando a la regresi√≥n lineal m√∫ltiple, el estimador cambia ligeramente:

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(\color{#e64173}{\tilde{x}_1},\,y)}{\mathop{\hat{\text{Var}}} \left( \color{#e64173}{\tilde{x}_1} \right)} $$

donde $\color{#e64173}{\tilde{x}_1}$ es la variable *residualizada* $x_1$, la variaci√≥n restante en $x$ despu√©s de controlar las otras variables explicativas.

---
M√°s formalmente, considere el modelo de regresi√≥n m√∫ltiple

$$ y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + u_i $$

Nuestro $x_{1}$ residualizado (que llamamos $\color{# e64173}{\tilde{x}_1}$) proviene de hacer una regresi√≥n de $x_1$ en una intersecci√≥n y todas las dem√°s variables explicativas y recopilar los residuos, _es decir_,

$$
\begin{aligned}
  \hat{x}_{1i} &= \hat{\gamma}_0 + \hat{\gamma}_2 \, x_{2i} + \hat{\gamma}_3 \, x_{3i} \\
  \color{#e64173}{\tilde{x}_{1i}} &= x_{1i} - \hat{x}_{1i}
\end{aligned}
$$

--

lo que nos permite comprender mejor nuestro estimador de regresi√≥n m√∫ltiple MCO ü§ì

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(\color{#e64173}{\tilde{x}_1},\,y)}{\mathop{\hat{\text{Var}}} \left( \color{#e64173}{\tilde{x}_1} \right)} $$
---
layout: false
class: clear, middle

```{R, venn_iv, echo = F, dev = "svg"}
# Colors (order: x1, x2, x3, y)
venn_colors <- c(purple, red, "grey60", orange)
# Locations of circles
venn_df <- tibble(
  x  = c( 0.0,   -0.5,    1.5,   -1.0),
  y  = c( 0.0,   -2.5,   -1.8,    2.0),
  r  = c( 1.9,    1.5,    1.5,    1.3),
  l  = c( "Y", "X[1]", "X[2]", "X[3]"),
  xl = c( 0.0,   -0.5,    1.6,   -1.0),
  yl = c( 0.0,   -2.5,   -1.9,    2.2)
)
# Venn
ggplot(data = venn_df, aes(x0 = x, y0 = y, r = r, fill = l, color = l)) +
geom_circle(alpha = 0.3, size = 0.75) +
theme_void() +
theme(legend.position = "none") +
scale_fill_manual(values = venn_colors) +
scale_color_manual(values = venn_colors) +
geom_text(aes(x = xl, y = yl, label = l), size = 9, family = "Fira Sans Book", parse = T) +
annotate(
  x = -5.5, y = 3.3,
  geom = "text", label = "Regresi√≥n M√∫ltiple", size = 9, family = "Fira Sans Book", hjust = 0
) +
xlim(-5.5, 4.5) +
ylim(-4.2, 3.4) +
coord_equal()
```

---
layout: true
# Regresi√≥n M√∫ltiple

---
## Ajuste del modelo

Las medidas de *bondad de ajuste* intentan analizar qu√© tan bien nuestro modelo describe (*ajusta*) los datos.

**Medida com√∫n:** $R^2$ [R-cuadrado] (*a.k.a.* coeficiente de determinaci√≥n)

$$ R^2 = \dfrac{\sum_i (\hat{y}_i - \overline{y})^2}{\sum_i \left( y_i - \overline{y} \right)^2} = 1 - \dfrac{\sum_i \left( y_i - \hat{y}_i \right)^2}{\sum_i \left( y_i - \overline{y} \right)^2} $$

Observe a nuestro viejo amigo SCR: $\sum_i \left( y_i - \hat{y}_i \right)^2 = \sum_i e_i^2$.

--

$R^2$ literalmente nos dice la parte de la varianza en $y$ que representan nuestros modelos actuales. Por lo tanto $0 \leq R^2 \leq 1$.

---

**El problema:** A medida que agregamos variables a nuestro modelo, el $R^2$ se incrementa *mec√°nicamente*.

--

Para ver este problema, podemos simular un conjunto de datos de 10.000 observaciones en $y$ y 1.000 variables aleatorias $x_k$. **¬°No hay relaciones entre $y$ y $x_k$!**

Esquema de pseudoc√≥digo de la simulaci√≥n:
--

.pseudocode-small[

- Generamos 10.000 observaciones de $y$
- Generamos 10.000 observaciones sobre las variables $x_1$ hasta $x_{1000}$
- Regresiones
  - LM<sub>1</sub>: Regresamos $y$ en $x_1$; registro R<sup>2</sup>
  - LM<sub>2</sub>: Regresamos $y$ en $x_1$ y $x_2$; registro R<sup>2</sup>
  - LM<sub>3</sub>: Regresamos $y$ en $x_1$, $x_2$, y $x_3$; registro R<sup>2</sup>
  - ...
  - LM<sub>1000</sub>: Regresamos $y$ en $x_1$, $x_2$, ..., $x_{1000}$; registro R<sup>2</sup>
]

---

**El problema:** A medida que agregamos variables a nuestro modelo, el $R^2$ se incrementa *mec√°nicamente*.

C√≥digo de .mono[R] para la simulaci√≥n:


```{R, r2 data code, eval = F, cache = T}
set.seed(1989)
y <- rnorm(1e4)
x <- matrix(data = rnorm(1e7), nrow = 1e4)
x %<>% cbind(matrix(data = 1, nrow = 1e4, ncol = 1), x)
r_df <- mclapply(X = 1:(1e3-1), mc.cores = 2, FUN = function(i) {
  tmp_reg <- lm(y ~ x[,1:(i+1)]) %>% summary()
  data.frame(
    k = i + 1,
    r2 = tmp_reg %$% r.squared,
    r2_adj = tmp_reg %$% adj.r.squared
  )
}) %>% bind_rows()
```

---

**El problema:** A medida que agregamos variables a nuestro modelo, el $\color{#314f4f}{R^2}$ se incrementa *mec√°nicamente*.

.center[
<img src = "images/r_2.png" width = "900">]

---

**Una soluci√≥n:** $\color{#e64173}{R^2}$ .pink[Ajustado] 


.center[
<img src = "images/r_2_adj.png" width = "900">]

---

**El problema:** A medida que agregamos variables a nuestro modelo, el $R^2$ se incrementa *mec√°nicamente*.

**Una soluci√≥n:** Penalizar por el n√∫mero de variables, _por ejemplo_, $R^2$ ajustado:

$$ \overline{R}^2 = 1 - \dfrac{\sum_i \left( y_i - \hat{y}_i \right)^2/(n-k-1)}{\sum_i \left( y_i - \overline{y} \right)^2/(n-1)} $$

*Nota:* El $R^2$ ajustado no necesita estar entre 0 y 1.

---
layout: false
class: inverse, middle
# Incertidumbre e inferencia

---
layout: true
# Incertidumbre e inferencia
## Aprendiendo de nuestros errores

---

Como se√±al√≥ nuestra simulaci√≥n anterior, nuestro problema con la **incertidumbre** es que no sabemos si nuestra estimaci√≥n muestral est√° *cerca* o *lejos* del par√°metro poblacional desconocido. <sup>.pink[‚Ä†]</sup>

Sin embargo, no todo est√° perdido. Podemos usar los errores $\left (e_i = y_i - \hat {y}_i\right)$ para tener una idea de qu√© tan bien nuestro modelo explica la variaci√≥n observada en $y$.

Cuando nuestro modelo parece estar haciendo un "buen" trabajo, es posible que tengamos un poco m√°s de confianza al usarlo para conocer la relaci√≥n entre $y$ y $x$.

Ahora solo tenemos que formalizar lo que realmente significa un "buen trabajo".

.footnote[.pink[‚Ä†]: Excepto cuando corremos la simulaci√≥n nosotros mismos, por eso nos gustan las simulaciones.]

---

En primer lugar, estimaremos la varianza de $u_i$ (recordemos: $\mathop{\text{Var}}\left(u_i \right) = \sigma^2$) usando nuestros errores al cuadrado, _es decir_,

$$ s^2 = \dfrac{\sum_i e_i^2}{n - k} $$

donde $k$ nos da el n√∫mero de t√©rminos de constantes y variables que estimamos, _ejemplo_, $\ beta_0$ y $\beta_1$ dar√≠an $k = 2$.

$s^2$ es un estimador insesgado de $\sigma^2$.

---

Luego mostramos que la varianza de $\hat{\beta}_1$ (para una regresi√≥n lineal simple) es

$$ \mathop{\text{Var}} \left( \hat{\beta}_1 \right) = \dfrac{s^2}{\sum_i \left( x_i - \overline{x} \right)^2} $$

lo que muestra que la varianza de nuestro estimador de pendiente:

1. aumenta a medida que nuestras residuos se vuelven m√°s ruidosas
2. disminuye a medida que aumenta la varianza de $x$


---


*M√°s com√∫nmente:* El **error est√°ndar** de $\hat{\beta}_1$

$$ \mathop{\hat{\text{EE}}} \left( \hat{\beta}_1 \right) = \sqrt{\dfrac{s^2}{\sum_i \left( x_i - \overline{x} \right)^2}} $$

*Recuerden:* El error est√°ndar de un estimador es la desviaci√≥n est√°ndar de la distribuci√≥n del estimador.

---

El error est√°ndar en .mono[R]'s `lm`, se ve as√≠:

```{R, se}
tidy(lm(y ~ x, pop_df))
```


---

Usamos el error est√°ndar de $\hat{\beta}_1$, junto con el propio $\hat{\beta}_1$, para aprender sobre el par√°metro $\beta_1$.

Despu√©s de derivar la distribuci√≥n de $\hat{\beta}_1$, <sup>.pink[‚Ä†]</sup> tenemos dos opciones (relacionadas) para la inferencia estad√≠stica formal (aprendizaje) sobre nuestro par√°metro desconocido $\beta_1$:

- **Intervalos de confianza:** Utilizar la estimaci√≥n y su error est√°ndar para crear un intervalo que, cuando se repite, generalmente <sup>.pink[‚Ä†‚Ä†]</sup> contendr√° el par√°metro verdadero.

- **Pruebas de hip√≥tesis:** Determinan si existe evidencia estad√≠sticamente significativa para rechazar un valor o rango de valores hipot√©ticos.

.footnote[
.pink[‚Ä†]: *Pista:* es normal con la media y la varianza que hemos derivado/discutido anteriormente)
<br>
.pink[‚Ä†‚Ä†]: _Ejemplo_, los intervalos de confianza del 95% construidos de manera similar contendr√°n el par√°metro verdadero el 95% del tiempo.
]


---
layout: true
# Incertidumbre e inferencia
## Intervalos de confianza

Construimos intervalos de confianza nivel $(1-\alpha)$ para $\beta_1$
$$ \hat{\beta}\_1 \pm t\_{\alpha/2,\text{gl}} \, \mathop{\hat{\text{EE}}} \left(\hat{\beta}\_1\right) $$

---

$t_{\alpha/2,\text{gl}}$ denota el $\alpha/2$ cuantial de una distribuci√≥n $t$ con $n-k$ grados de libertad.

---

Por ejemplo, 100 obs., dos coeficientes (_es decir_, $\hat{\beta}_0$ y $\hat{\beta}_1 \ \text{implica} \ k = 2$) y $\alpha = 0.05$ (para un intervalo de confianza del 95%) nos da $t_ {0.025, \, 98} = `r qt(0.025, 98)%>% round (2)`$


```{R, t dist, echo = F, dev = "svg", fig.height = 3}
d6 <- tibble(x = seq(-4, 4, 0.01), y = dt(x, df = 98)) %>%
  rbind(., tibble(x = seq(4, -4, -0.01), y = 0))
ggplot() +
geom_polygon(data = d6, aes(x, y), fill = "grey85") +
geom_polygon(data = d6 %>% filter(x <= qt(0.025, 98)), aes(x, y), fill = red_pink) +
geom_hline(yintercept = 0, color = "black") +
geom_vline(xintercept = qt(0.025, 98), size = 0.35, linetype = "solid") +
theme_simple +
theme(axis.text.x = element_text(size = 12))
```

---

**Ejemplo:**
```{R ci r output, echo = T, highlight.output = 5}
lm(y ~ x, data = pop_df) %>% tidy()
```

--


Nuestro intervalo de confianza del 95% es $0.567\pm1.98\times0.0793= \left[0.410, \, 0.724 \right]$

---
layout: true
# Incertidumbre e inferencia
## Intervalos de confianza

---

As√≠ que tenemos un intervalo de confianza para $\beta_1$, _i.e._, $\left[ 0.410,\, 0.724 \right]$.

Y... ¬øqu√© significa?

--

**Informalmente:** El intervalo de confianza nos da una regi√≥n (intervalo) en la que podemos depositar algo de confianza (confianza) para contener el par√°metro.

-

**M√°s formalmente:** Si muestrea repetidamente de nuestra poblaci√≥n y construye intervalos de confianza para cada una de estas muestras, $(1- \alpha)$ por ciento de nuestros intervalos (_ejemplo_, 95%) contendr√° el par√°metro de poblaci√≥n *en alg√∫n lugar del intervalo*.

--

De nuevo a nuestra simulaci√≥n...

---
Extrajimos 10.000 muestras (cada una de tama√±o $n = 30$) de nuestra poblaci√≥n y estimamos nuestro modelo de regresi√≥n para cada una de estas simulaciones:

$$ y_i = \hat {\beta}_0 + \hat{\beta}_1 x_i + e_i $$
<center> (repetido 10.000 veces) </center>

Ahora, estimemos intervalos de confianza del 95% para cada uno de estos intervalos...
---

```{R, simulation ci data, include = F}
# Create confidence intervals for b1
ci_df <- sim_df %>% filter(term == "x") %>%
  mutate(
    lb = estimate - std.error * qt(.975, 28),
    ub = estimate + std.error * qt(.975, 28),
    ci_contains = (lm0$coefficients[2] >= lb) & (lm0$coefficients[2] <= ub),
    ci_above = lm0$coefficients[2] < lb,
    ci_below = lm0$coefficients[2] > ub,
    ci_group = 2 * ci_above + (!ci_below)
  ) %>%
  arrange(ci_group, estimate) %>%
  mutate(x = 1:1e4)
```

**De nuestras simulaciones previas:** `r ci_df$ci_contains %>% multiply_by(100) %>% mean() %>% round(1)`% el 95% de los intervalos de confianza contienen el verdadero valor de par√°metro de $\beta_1$.

```{R, simulation ci, echo = F, dev = "svg", fig.height = 5.5}
# Plot
ggplot(data = ci_df) +
geom_segment(aes(y = lb, yend = ub, x = x, xend = x, color = ci_contains)) +
geom_hline(yintercept = lm0$coefficients[2]) +
scale_y_continuous(breaks = lm0$coefficients[2], labels = TeX("$\\beta_1$")) +
scale_color_manual(values = c(red_pink, "grey85")) +
theme_simple +
theme(
  axis.text.x = element_blank(),
  axis.text.y = element_text(size = 18)
)
```

---
layout: true
# Incertidumbre e inferencia
## Testeo de hipotesis

---

En muchas aplicaciones, queremos saber m√°s que una estimaci√≥n puntual o un rango de valores. Queremos saber qu√© dice nuestra evidencia estad√≠stica sobre las teor√≠as existentes.

Queremos probar hip√≥tesis planteadas por funcionarios, pol√≠ticos, economistas, cient√≠ficos, amigos, vecinos raros, *etc√©tera*.

.hi-slate[Ejemplos]

- ¬øEl aumento de la presencia policial **reduce la delincuencia**?
- ¬øConstruir un muro gigante **reduce el crimen**?
- ¬øEl cierre de un gobierno **afecta negativamente a la econom√≠a**?
- ¬øEl cannabis legal **reduce la conducci√≥n en estado de ebriedad** o **reduce el uso de opi√°ceos**?
- ¬øLos est√°ndares de calidad del aire **aumentan la salud** y/o **reducen el empleo**?

---

La prueba de hip√≥tesis se basa en resultados e intuici√≥n muy similares.

Si bien la incertidumbre ciertamente existe, a√∫n podemos construir pruebas estad√≠sticas *confiables* (rechazando o no rechazando una hip√≥tesis planteada).

--

.hi-slate[MCO prueba *t*] Nuestra hip√≥tesis (nula) establece que $\beta_1$ es igual a un valor $c$, _por ejemplo_, $\left.H_{0} \ \right) \beta_{1}=0$

Bajo los supuestos del modelo lineal cl√°sico (MLC),

$$ t_\text{estad√≠stico} = \dfrac{\hat{\beta}_1 - c}{\mathop{\hat{\text{EE}}} \left( \hat{\beta}_1 \right)} $$

sigue una distribuci√≥n $t$ con $n-k$ grados de libertad.

---

Para una prueba **de dos caras** de nivel $\alpha $, rechazamos la hip√≥tesis nula (y concluimos con la hip√≥tesis alternativa) cuando

$$ \left|t\_\text{estad√≠stico}\right| > \left|t\_{1-\alpha/2,\,df}\right| $$
lo que significa que nuestra **estad√≠stica de prueba es m√°s extrema que el valor cr√≠tico**.

Alternativamente, podemos calcular el **valor p** que acompa√±a a nuestra estad√≠stica de prueba, que efectivamente nos da la probabilidad de ver nuestra estad√≠stica de prueba *o una estad√≠stica de prueba m√°s extrema* si la hip√≥tesis nula fuera cierta.

Valores p muy peque√±os (generalmente < 0.05) significan que ser√≠a improbable ver nuestros resultados si la hipotesis nula fuera realmente cierta; tendemos a rechazar el valor nulo para valores p por debajo de 0.05.

---

.mono[R] y .mono[Stata] testean por defecto contra el valor cero.

```{R hypothesis test, echo = T, highlight.output = 5}
lm(y ~ x, data = pop_df) %>% tidy()
```
--

$\left.H_{0} \ \right)\ \beta_1 = 0$ *vs.* $\left.H_{1} \ \right)\ \beta_1 \neq 0$

¬øQu√© observamos del valor-p?

El valor-*p* $< 0.05$. 

--

 $t_\text{stat} = 7.15$ y $t_\text{0.975, 28} = `r qt(0.975, 28) %>% round(2)`$
--
 lo que implica que el valor-*p* $< 0.05$. 

--

Entonces, .hi[rechazamos H.sub[0]].

---

¬°De vuelta a nuestra simulaci√≥n! Veamos qu√© est√° haciendo realmente nuestra estad√≠stica de $t$.

En esta situaci√≥n, podemos conocer (y hacer cumplir) la hip√≥tesis nula, ya que generamos los datos.

Para cada una de las 10.000 muestras, calcularemos la estad√≠stica $t$, y luego podremos ver cu√°ntas estad√≠sticas de $t$ exceden nuestro valor cr√≠tico (`r qt(0.975, 28) %>% round (2)`, como encima).

La respuesta deber√≠a ser aproximadamente el 5 por ciento, nuestro nivel $\alpha$.

---
layout: true
# Incertidumbre e inferencia

---

```{R, simulation t data, include = F}
# Calculate test statistics
t_df <- sim_df %>%
  filter(term == "x") %>%
  mutate(
    t_stat = (estimate - lm0$coefficients[2]) / std.error,
    reject = abs(t_stat) > abs(qt(0.975, 28))
  )
t_density <- density(t_df$t_stat, from = -5, to = 4) %$%
  data.frame(x = x, y = y) %>%
  mutate(area = abs(x) > abs(qt(0.975, 28)))
```

En nuestra simulaci√≥n, el porcentaje `r t_df$reject %>% mean() %>% multiply_by(100) %>% round(1)` de nuestras estad√≠sticas de $t$ rechaza la hip√≥tesis nula.

La distribuci√≥n de nuestras estad√≠sticas de $t$ (sombreando las regiones de rechazo).

```{R, simulation t plot, echo = F, dev = "svg", fig.height = 5.75}
ggplot(data = t_density, aes(x = x, ymin = 0, ymax = y)) +
geom_vline(xintercept = 0) +
geom_ribbon(fill = "grey85", alpha = 0.8) +
geom_ribbon(
  data = t_density %>% filter(x < qt(0.025, 28)),
  fill = red_pink
) +
geom_ribbon(
  data = t_density %>% filter(x > qt(0.975, 28)),
  fill = red_pink
) +
geom_hline(yintercept = 0) +
# geom_vline(xintercept = qt(c(0.025, 0.975), df = 28), color = red_pink) +
theme_simple
```

---

```{R, simulation p data, include = F}
# Calculate test statistics
p_df <- sim_df %>%
  filter(term == "x") %>%
  mutate(
    p_value = 2 * pt(
      q = abs((estimate - lm0$coefficients[2]) / std.error),
      df = 28,
      lower.tail = F
    ),
    reject = p_value < 0.05
  )
p_density <- density(p_df$p_value, from = 0, to = 1) %$%
  data.frame(x = x, y = y) %>%
  mutate(area = x < 0.05)
```

En consecuencia, `r p_df$reject %>% mean() %>% multiply_by(100) %>% round(1)` % de nuestros p-valores rechazan la hip√≥tesis nula.

La distribuci√≥n de nuestros valores p (sombreando los valores p por debajo de 0,05).
```{R, simulation p plot, echo = F, dev = "svg", fig.height = 5.75}
ggplot(data = p_density, aes(x = x, ymin = 0, ymax = y)) +
geom_vline(xintercept = 0) +
geom_ribbon(fill = "grey85", alpha = 0.8) +
geom_ribbon(
  data = p_density %>% filter(x < 0.05),
  fill = red_pink
) +
geom_hline(yintercept = 0) +
theme_simple
```

---
layout: false
class: inverse, middle
# Aplicaciones en .mono[R]

---
#Ejercicio C3.1 (Wooldridge)

.center[
<img src="images/c3_1.png" width="800">]
---
#Ejercicio C3.2 (Wooldridge)

.center[
<img src="images/c3_2.png" width="800">]
---
#Ejercicio C3.4 (Wooldridge)

.center[
<img src="images/c3_4.png" width="800">]

---
Se dispone de una muestra de 30 observaciones de datos que 	representan salario y experiencia laboral de economistas de Montevideo en 2013 y 2014. Las variables son: $y$ = salario (en miles USD); $x$ = experiencia posterior a recibirse (a√±os).

Se tiene el siguiente modelo:

$$\mathrm{y}_{\mathrm{i}}=\beta_{1}+\beta_{2} \mathrm{x}_{\mathrm{i}}+\varepsilon_{\mathrm{i}}$$
Se sabe que:

$$\sum_{i=1}^{30} y_{i}^{2}=65692,27 \ ; \sum_{i=1}^{30} y_{i}=1365,1 \ ; \sum_{i=1}^{30} y_{i} x_{i}=26046,9$$
$$\sum_{i=1}^{30} x_{i}^{2}=12230 \ ; \ \sum_{i=1}^{30} x_{i}=550$$
$$\mathrm{SCR}=3089,95 \ ; \mathrm{SCT}=3574,67$$

---
1.1	Estime por m√≠nimos cuadrados ordinarios los par√°metros de dicho modelo.

1.2	Calcule la matriz de varianzas y covarianzas de los coeficientes estimados.

1.3	Interprete los resultados obtenidos y analice su significancia estad√≠stica.

1.4	Calcular el R2 del modelo. ¬øQu√© puede decir al respecto?

1.5	¬øQu√© relaci√≥n deber√≠a encontrarse entre el vector de residuos y las variables explicativas?


---

.center[
<img src="images/ej.png" width="800">]
