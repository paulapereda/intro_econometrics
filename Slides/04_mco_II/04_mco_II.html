<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>MCO: inferencia y m√°s</title>
    <meta charset="utf-8" />
    <meta name="author" content="Paula Pereda (ppereda@correo.um.edu.uy)" />
    <link href="04_mco_II_files/remark-css/default.css" rel="stylesheet" />
    <link href="04_mco_II_files/remark-css/metropolis.css" rel="stylesheet" />
    <link href="04_mco_II_files/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# MCO: inferencia y m√°s
## Econometr√≠a I
### Paula Pereda (<a href="mailto:ppereda@correo.um.edu.uy" class="email">ppereda@correo.um.edu.uy</a>)
### 10 de setiembre de 2021

---

class: inverse, middle








# Regresi√≥n m√∫ltiple

---
layout: true
# Regresi√≥n m√∫ltiple

---

## M√°s variables explicativas


Pasamos de la **regresi√≥n lineal simple** (una .pink[variable de resultado] y una .purple[variable explicativa])

$$ \color{#e64173}{y_i} = \beta_0 + \beta_1 \color{#6A5ACD}{x_i} + u_i $$

a la tierra de la **regresi√≥n lineal m√∫ltiple** (un .pink[variable de resultado] y varios .purple[variables explicativas])

$$ \color{#e64173}{y\_i} = \beta\_0 + \beta\_1 \color{#6A5ACD}{x\_{1i}} + \beta\_2 \color{#6A5ACD}{x\_{2i}} + \cdots + \beta\_k \color{#6A5ACD}{x\_{ki}} + u\_i $$

--

**¬øPor qu√©?**
--
 Podemos explicar mejor la variaci√≥n en `\(y\)`, mejorar las predicciones, evitar el sesgo de variables omitidas, ...

---



`\(y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + u_i \quad\)` `\(x_1\)` es continua `\(\quad x_2\)` es categ√≥rica

&lt;img src="04_mco_II_files/figure-html/mult reg plot 1-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false

La intercepci√≥n y la variable categ√≥rica `\(x_2\)` controlan las medias de los grupos.

&lt;img src="04_mco_II_files/figure-html/mult reg plot 2-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false

Con los medias de los grupos eliminados:

&lt;img src="04_mco_II_files/figure-html/mult reg plot 3-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false

`\(\hat{\beta}_1\)` estima la relaci√≥n la relaci√≥n entre `\(y\)` y `\(x_1\)` despu√©s de controlar por `\(x_2\)`.

&lt;img src="04_mco_II_files/figure-html/mult reg plot 4-1.svg" style="display: block; margin: auto;" /&gt;

---
count: false

Otra manera de pensar sobre esto:

&lt;img src="04_mco_II_files/figure-html/mult reg plot 5-1.svg" style="display: block; margin: auto;" /&gt;

---
Mirar a nuestro estimador puede ayudar, tambi√©n. 

Para una regresi√≥n simple `\(y_i = \beta_0 + \beta_1 x_i + u_i\)`

$$
`\begin{aligned}
  \hat{\beta}_1 &amp;= \\[0.3em]
  &amp;= \dfrac{\sum_i \left( x_i - \overline{x} \right) \left( y_i - \overline{y} \right)}{\sum_i \left( x_i -\overline{x} \right)} \\[0.3em]
  &amp;= \dfrac{\sum_i \left( x_i - \overline{x} \right) \left( y_i - \overline{y} \right)/(n-1)}{\sum_i \left( x_i -\overline{x} \right) / (n-1)} \\[0.3em]
  &amp;= \dfrac{\mathop{\hat{\text{Cov}}}(x,\,y)}{\mathop{\hat{\text{Var}}} \left( x \right)}
\end{aligned}`
$$

---
El estimador de regresi√≥n simple:

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(x,\,y)}{\mathop{\hat{\text{Var}}} \left( x \right)} $$

Pasando a la regresi√≥n lineal m√∫ltiple, el estimador cambia ligeramente:

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(\color{#e64173}{\tilde{x}_1},\,y)}{\mathop{\hat{\text{Var}}} \left( \color{#e64173}{\tilde{x}_1} \right)} $$

donde `\(\color{#e64173}{\tilde{x}_1}\)` es la variable *residualizada* `\(x_1\)`, la variaci√≥n restante en `\(x\)` despu√©s de controlar las otras variables explicativas.

---
M√°s formalmente, considere el modelo de regresi√≥n m√∫ltiple

$$ y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + u_i $$

Nuestro `\(x_{1}\)` residualizado (que llamamos `\(\color{# e64173}{\tilde{x}_1}\)`) proviene de hacer una regresi√≥n de `\(x_1\)` en una intersecci√≥n y todas las dem√°s variables explicativas y recopilar los residuos, _es decir_,

$$
`\begin{aligned}
  \hat{x}_{1i} &amp;= \hat{\gamma}_0 + \hat{\gamma}_2 \, x_{2i} + \hat{\gamma}_3 \, x_{3i} \\
  \color{#e64173}{\tilde{x}_{1i}} &amp;= x_{1i} - \hat{x}_{1i}
\end{aligned}`
$$

--

lo que nos permite comprender mejor nuestro estimador de regresi√≥n m√∫ltiple MCO ü§ì

$$ \hat{\beta}_1 = \dfrac{\mathop{\hat{\text{Cov}}}(\color{#e64173}{\tilde{x}_1},\,y)}{\mathop{\hat{\text{Var}}} \left( \color{#e64173}{\tilde{x}_1} \right)} $$
---
layout: false
class: clear, middle

&lt;img src="04_mco_II_files/figure-html/venn_iv-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: true
# Regresi√≥n M√∫ltiple

---
## Ajuste del modelo

Las medidas de *bondad de ajuste* intentan analizar qu√© tan bien nuestro modelo describe (*ajusta*) los datos.

**Medida com√∫n:** `\(R^2\)` [R-cuadrado] (*a.k.a.* coeficiente de determinaci√≥n)

$$ R^2 = \dfrac{\sum_i (\hat{y}_i - \overline{y})^2}{\sum_i \left( y_i - \overline{y} \right)^2} = 1 - \dfrac{\sum_i \left( y_i - \hat{y}_i \right)^2}{\sum_i \left( y_i - \overline{y} \right)^2} $$

Observe a nuestro viejo amigo SCR: `\(\sum_i \left( y_i - \hat{y}_i \right)^2 = \sum_i e_i^2\)`.

--

`\(R^2\)` literalmente nos dice la parte de la varianza en `\(y\)` que representan nuestros modelos actuales. Por lo tanto `\(0 \leq R^2 \leq 1\)`.

---

**El problema:** A medida que agregamos variables a nuestro modelo, el `\(R^2\)` se incrementa *mec√°nicamente*.

--

Para ver este problema, podemos simular un conjunto de datos de 10.000 observaciones en `\(y\)` y 1.000 variables aleatorias `\(x_k\)`. **¬°No hay relaciones entre `\(y\)` y `\(x_k\)`!**

Esquema de pseudoc√≥digo de la simulaci√≥n:
--

.pseudocode-small[

- Generamos 10.000 observaciones de `\(y\)`
- Generamos 10.000 observaciones sobre las variables `\(x_1\)` hasta `\(x_{1000}\)`
- Regresiones
  - LM&lt;sub&gt;1&lt;/sub&gt;: Regresamos `\(y\)` en `\(x_1\)`; registro R&lt;sup&gt;2&lt;/sup&gt;
  - LM&lt;sub&gt;2&lt;/sub&gt;: Regresamos `\(y\)` en `\(x_1\)` y `\(x_2\)`; registro R&lt;sup&gt;2&lt;/sup&gt;
  - LM&lt;sub&gt;3&lt;/sub&gt;: Regresamos `\(y\)` en `\(x_1\)`, `\(x_2\)`, y `\(x_3\)`; registro R&lt;sup&gt;2&lt;/sup&gt;
  - ...
  - LM&lt;sub&gt;1000&lt;/sub&gt;: Regresamos `\(y\)` en `\(x_1\)`, `\(x_2\)`, ..., `\(x_{1000}\)`; registro R&lt;sup&gt;2&lt;/sup&gt;
]

---

**El problema:** A medida que agregamos variables a nuestro modelo, el `\(R^2\)` se incrementa *mec√°nicamente*.

C√≥digo de .mono[R] para la simulaci√≥n:



```r
set.seed(1989)
y &lt;- rnorm(1e4)
x &lt;- matrix(data = rnorm(1e7), nrow = 1e4)
x %&lt;&gt;% cbind(matrix(data = 1, nrow = 1e4, ncol = 1), x)
r_df &lt;- mclapply(X = 1:(1e3-1), mc.cores = 2, FUN = function(i) {
  tmp_reg &lt;- lm(y ~ x[,1:(i+1)]) %&gt;% summary()
  data.frame(
    k = i + 1,
    r2 = tmp_reg %$% r.squared,
    r2_adj = tmp_reg %$% adj.r.squared
  )
}) %&gt;% bind_rows()
```

---

**El problema:** A medida que agregamos variables a nuestro modelo, el `\(\color{#314f4f}{R^2}\)` se incrementa *mec√°nicamente*.

.center[
&lt;img src = "images/r_2.png" width = "900"&gt;]

---

**Una soluci√≥n:** `\(\color{#e64173}{R^2}\)` .pink[Ajustado] 


.center[
&lt;img src = "images/r_2_adj.png" width = "900"&gt;]

---

**El problema:** A medida que agregamos variables a nuestro modelo, el `\(R^2\)` se incrementa *mec√°nicamente*.

**Una soluci√≥n:** Penalizar por el n√∫mero de variables, _por ejemplo_, `\(R^2\)` ajustado:

$$ \overline{R}^2 = 1 - \dfrac{\sum_i \left( y_i - \hat{y}_i \right)^2/(n-k-1)}{\sum_i \left( y_i - \overline{y} \right)^2/(n-1)} $$

*Nota:* El `\(R^2\)` ajustado no necesita estar entre 0 y 1.

---
layout: false
class: inverse, middle
# Incertidumbre e inferencia

---
layout: true
# Incertidumbre e inferencia
## Aprendiendo de nuestros errores

---

Como se√±al√≥ nuestra simulaci√≥n anterior, nuestro problema con la **incertidumbre** es que no sabemos si nuestra estimaci√≥n muestral est√° *cerca* o *lejos* del par√°metro poblacional desconocido. &lt;sup&gt;.pink[‚Ä†]&lt;/sup&gt;

Sin embargo, no todo est√° perdido. Podemos usar los errores `\(\left (e_i = y_i - \hat {y}_i\right)\)` para tener una idea de qu√© tan bien nuestro modelo explica la variaci√≥n observada en `\(y\)`.

Cuando nuestro modelo parece estar haciendo un "buen" trabajo, es posible que tengamos un poco m√°s de confianza al usarlo para conocer la relaci√≥n entre `\(y\)` y `\(x\)`.

Ahora solo tenemos que formalizar lo que realmente significa un "buen trabajo".

.footnote[.pink[‚Ä†]: Excepto cuando corremos la simulaci√≥n nosotros mismos, por eso nos gustan las simulaciones.]

---

En primer lugar, estimaremos la varianza de `\(u_i\)` (recordemos: `\(\mathop{\text{Var}}\left(u_i \right) = \sigma^2\)`) usando nuestros errores al cuadrado, _es decir_,

$$ s^2 = \dfrac{\sum_i e_i^2}{n - k} $$

donde `\(k\)` nos da el n√∫mero de t√©rminos de constantes y variables que estimamos, _ejemplo_, `\(\ beta_0\)` y `\(\beta_1\)` dar√≠an `\(k = 2\)`.

`\(s^2\)` es un estimador insesgado de `\(\sigma^2\)`.

---

Luego mostramos que la varianza de `\(\hat{\beta}_1\)` (para una regresi√≥n lineal simple) es

$$ \mathop{\text{Var}} \left( \hat{\beta}_1 \right) = \dfrac{s^2}{\sum_i \left( x_i - \overline{x} \right)^2} $$

lo que muestra que la varianza de nuestro estimador de pendiente:

1. aumenta a medida que nuestras residuos se vuelven m√°s ruidosas
2. disminuye a medida que aumenta la varianza de `\(x\)`


---


*M√°s com√∫nmente:* El **error est√°ndar** de `\(\hat{\beta}_1\)`

$$ \mathop{\hat{\text{EE}}} \left( \hat{\beta}_1 \right) = \sqrt{\dfrac{s^2}{\sum_i \left( x_i - \overline{x} \right)^2}} $$

*Recuerden:* El error est√°ndar de un estimador es la desviaci√≥n est√°ndar de la distribuci√≥n del estimador.

---

El error est√°ndar en .mono[R]'s `lm`, se ve as√≠:


```r
tidy(lm(y ~ x, pop_df))
```

```
&gt; # A tibble: 2 x 5
&gt;   term        estimate std.error statistic  p.value
&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
&gt; 1 (Intercept)    2.53     0.422       6.00 3.38e- 8
&gt; 2 x              0.567    0.0793      7.15 1.59e-10
```


---

Usamos el error est√°ndar de `\(\hat{\beta}_1\)`, junto con el propio `\(\hat{\beta}_1\)`, para aprender sobre el par√°metro `\(\beta_1\)`.

Despu√©s de derivar la distribuci√≥n de `\(\hat{\beta}_1\)`, &lt;sup&gt;.pink[‚Ä†]&lt;/sup&gt; tenemos dos opciones (relacionadas) para la inferencia estad√≠stica formal (aprendizaje) sobre nuestro par√°metro desconocido `\(\beta_1\)`:

- **Intervalos de confianza:** Utilizar la estimaci√≥n y su error est√°ndar para crear un intervalo que, cuando se repite, generalmente &lt;sup&gt;.pink[‚Ä†‚Ä†]&lt;/sup&gt; contendr√° el par√°metro verdadero.

- **Pruebas de hip√≥tesis:** Determinan si existe evidencia estad√≠sticamente significativa para rechazar un valor o rango de valores hipot√©ticos.

.footnote[
.pink[‚Ä†]: *Pista:* es normal con la media y la varianza que hemos derivado/discutido anteriormente)
&lt;br&gt;
.pink[‚Ä†‚Ä†]: _Ejemplo_, los intervalos de confianza del 95% construidos de manera similar contendr√°n el par√°metro verdadero el 95% del tiempo.
]


---
layout: true
# Incertidumbre e inferencia
## Intervalos de confianza

Construimos intervalos de confianza nivel `\((1-\alpha)\)` para `\(\beta_1\)`
$$ \hat{\beta}\_1 \pm t\_{\alpha/2,\text{gl}} \, \mathop{\hat{\text{EE}}} \left(\hat{\beta}\_1\right) $$

---

`\(t_{\alpha/2,\text{gl}}\)` denota el `\(\alpha/2\)` cuantial de una distribuci√≥n `\(t\)` con `\(n-k\)` grados de libertad.

---

Por ejemplo, 100 obs., dos coeficientes (_es decir_, `\(\hat{\beta}_0\)` y `\(\hat{\beta}_1 \ \text{implica} \ k = 2\)`) y `\(\alpha = 0.05\)` (para un intervalo de confianza del 95%) nos da `\(t_ {0.025, \, 98} = -1.98\)`


&lt;img src="04_mco_II_files/figure-html/t dist-1.svg" style="display: block; margin: auto;" /&gt;

---

**Ejemplo:**

```r
lm(y ~ x, data = pop_df) %&gt;% tidy()
```

```
&gt; # A tibble: 2 x 5
&gt;   term        estimate std.error statistic  p.value
&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
&gt; 1 (Intercept)    2.53     0.422       6.00 3.38e- 8
*&gt; 2 x              0.567    0.0793      7.15 1.59e-10
```

--


Nuestro intervalo de confianza del 95% es `\(0.567\pm1.98\times0.0793= \left[0.410, \, 0.724 \right]\)`

---
layout: true
# Incertidumbre e inferencia
## Intervalos de confianza

---

As√≠ que tenemos un intervalo de confianza para `\(\beta_1\)`, _i.e._, `\(\left[ 0.410,\, 0.724 \right]\)`.

Y... ¬øqu√© significa?

--

**Informalmente:** El intervalo de confianza nos da una regi√≥n (intervalo) en la que podemos depositar algo de confianza (confianza) para contener el par√°metro.

-

**M√°s formalmente:** Si muestrea repetidamente de nuestra poblaci√≥n y construye intervalos de confianza para cada una de estas muestras, `\((1- \alpha)\)` por ciento de nuestros intervalos (_ejemplo_, 95%) contendr√° el par√°metro de poblaci√≥n *en alg√∫n lugar del intervalo*.

--

De nuevo a nuestra simulaci√≥n...

---
Extrajimos 10.000 muestras (cada una de tama√±o `\(n = 30\)`) de nuestra poblaci√≥n y estimamos nuestro modelo de regresi√≥n para cada una de estas simulaciones:

$$ y_i = \hat {\beta}_0 + \hat{\beta}_1 x_i + e_i $$
&lt;center&gt; (repetido 10.000 veces) &lt;/center&gt;

Ahora, estimemos intervalos de confianza del 95% para cada uno de estos intervalos...
---



**De nuestras simulaciones previas:** 97.6% el 95% de los intervalos de confianza contienen el verdadero valor de par√°metro de `\(\beta_1\)`.

&lt;img src="04_mco_II_files/figure-html/simulation ci-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: true
# Incertidumbre e inferencia
## Testeo de hipotesis

---

En muchas aplicaciones, queremos saber m√°s que una estimaci√≥n puntual o un rango de valores. Queremos saber qu√© dice nuestra evidencia estad√≠stica sobre las teor√≠as existentes.

Queremos probar hip√≥tesis planteadas por funcionarios, pol√≠ticos, economistas, cient√≠ficos, amigos, vecinos raros, *etc√©tera*.

.hi-slate[Ejemplos]

- ¬øEl aumento de la presencia policial **reduce la delincuencia**?
- ¬øConstruir un muro gigante **reduce el crimen**?
- ¬øEl cierre de un gobierno **afecta negativamente a la econom√≠a**?
- ¬øEl cannabis legal **reduce la conducci√≥n en estado de ebriedad** o **reduce el uso de opi√°ceos**?
- ¬øLos est√°ndares de calidad del aire **aumentan la salud** y/o **reducen el empleo**?

---

La prueba de hip√≥tesis se basa en resultados e intuici√≥n muy similares.

Si bien la incertidumbre ciertamente existe, a√∫n podemos construir pruebas estad√≠sticas *confiables* (rechazando o no rechazando una hip√≥tesis planteada).

--

.hi-slate[MCO prueba *t*] Nuestra hip√≥tesis (nula) establece que `\(\beta_1\)` es igual a un valor `\(c\)`, _por ejemplo_, `\(\left.H_{0} \ \right) \beta_{1}=0\)`

Bajo los supuestos del modelo lineal cl√°sico (MLC),

$$ t_\text{estad√≠stico} = \dfrac{\hat{\beta}_1 - c}{\mathop{\hat{\text{EE}}} \left( \hat{\beta}_1 \right)} $$

sigue una distribuci√≥n `\(t\)` con `\(n-k\)` grados de libertad.

---

Para una prueba **de dos caras** de nivel $\alpha $, rechazamos la hip√≥tesis nula (y concluimos con la hip√≥tesis alternativa) cuando

$$ \left|t\_\text{estad√≠stico}\right| &gt; \left|t\_{1-\alpha/2,\,df}\right| $$
lo que significa que nuestra **estad√≠stica de prueba es m√°s extrema que el valor cr√≠tico**.

Alternativamente, podemos calcular el **valor p** que acompa√±a a nuestra estad√≠stica de prueba, que efectivamente nos da la probabilidad de ver nuestra estad√≠stica de prueba *o una estad√≠stica de prueba m√°s extrema* si la hip√≥tesis nula fuera cierta.

Valores p muy peque√±os (generalmente &lt; 0.05) significan que ser√≠a improbable ver nuestros resultados si la hipotesis nula fuera realmente cierta; tendemos a rechazar el valor nulo para valores p por debajo de 0.05.

---

.mono[R] y .mono[Stata] testean por defecto contra el valor cero.


```r
lm(y ~ x, data = pop_df) %&gt;% tidy()
```

```
&gt; # A tibble: 2 x 5
&gt;   term        estimate std.error statistic  p.value
&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
&gt; 1 (Intercept)    2.53     0.422       6.00 3.38e- 8
*&gt; 2 x              0.567    0.0793      7.15 1.59e-10
```
--

`\(\left.H_{0} \ \right)\ \beta_1 = 0\)` *vs.* `\(\left.H_{1} \ \right)\ \beta_1 \neq 0\)`

¬øQu√© observamos del valor-p?

El valor-*p* `\(&lt; 0.05\)`. 

--

 `\(t_\text{stat} = 7.15\)` y `\(t_\text{0.975, 28} = 2.05\)`
--
 lo que implica que el valor-*p* `\(&lt; 0.05\)`. 

--

Entonces, .hi[rechazamos H.sub[0]].

---

¬°De vuelta a nuestra simulaci√≥n! Veamos qu√© est√° haciendo realmente nuestra estad√≠stica de `\(t\)`.

En esta situaci√≥n, podemos conocer (y hacer cumplir) la hip√≥tesis nula, ya que generamos los datos.

Para cada una de las 10.000 muestras, calcularemos la estad√≠stica `\(t\)`, y luego podremos ver cu√°ntas estad√≠sticas de `\(t\)` exceden nuestro valor cr√≠tico (2.05, como encima).

La respuesta deber√≠a ser aproximadamente el 5 por ciento, nuestro nivel `\(\alpha\)`.

---
layout: true
# Incertidumbre e inferencia

---



En nuestra simulaci√≥n, el porcentaje 2.4 de nuestras estad√≠sticas de `\(t\)` rechaza la hip√≥tesis nula.

La distribuci√≥n de nuestras estad√≠sticas de `\(t\)` (sombreando las regiones de rechazo).

&lt;img src="04_mco_II_files/figure-html/simulation t plot-1.svg" style="display: block; margin: auto;" /&gt;

---



En consecuencia, 2.4 % de nuestros p-valores rechazan la hip√≥tesis nula.

La distribuci√≥n de nuestros valores p (sombreando los valores p por debajo de 0,05).
&lt;img src="04_mco_II_files/figure-html/simulation p plot-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: false
class: inverse, middle
# Aplicaciones en .mono[R]

---
#Ejercicio C3.1 (Wooldridge)

.center[
&lt;img src="images/c3_1.png" width="800"&gt;]
---
#Ejercicio C3.2 (Wooldridge)

.center[
&lt;img src="images/c3_2.png" width="800"&gt;]
---
#Ejercicio C3.4 (Wooldridge)

.center[
&lt;img src="images/c3_4.png" width="800"&gt;]

---
Se dispone de una muestra de 30 observaciones de datos que 	representan salario y experiencia laboral de economistas de Montevideo en 2013 y 2014. Las variables son: `\(y\)` = salario (en miles USD); `\(x\)` = experiencia posterior a recibirse (a√±os).

Se tiene el siguiente modelo:

`$$\mathrm{y}_{\mathrm{i}}=\beta_{1}+\beta_{2} \mathrm{x}_{\mathrm{i}}+\varepsilon_{\mathrm{i}}$$`
Se sabe que:

`$$\sum_{i=1}^{30} y_{i}^{2}=65692,27 \ ; \sum_{i=1}^{30} y_{i}=1365,1 \ ; \sum_{i=1}^{30} y_{i} x_{i}=26046,9$$`
`$$\sum_{i=1}^{30} x_{i}^{2}=12230 \ ; \ \sum_{i=1}^{30} x_{i}=550$$`
`$$\mathrm{SCR}=3089,95 \ ; \mathrm{SCT}=3574,67$$`

---
1.1	Estime por m√≠nimos cuadrados ordinarios los par√°metros de dicho modelo.

1.2	Calcule la matriz de varianzas y covarianzas de los coeficientes estimados.

1.3	Interprete los resultados obtenidos y analice su significancia estad√≠stica.

1.4	Calcular el R2 del modelo. ¬øQu√© puede decir al respecto?

1.5	¬øQu√© relaci√≥n deber√≠a encontrarse entre el vector de residuos y las variables explicativas?


---

.center[
&lt;img src="images/ej.png" width="800"&gt;]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
